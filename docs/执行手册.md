# HullTactical-MarketPredict 项目执行手册

## 1. 项目概览
- 目标：基于 Kaggle Hull Tactical Market Prediction 数据集构建稳健的市场预测模型，并产出可提交的 `submission.csv`。
- 原则：时间顺序严守、特征管线可复用、实验记录可追溯、提交流程可复现。
- 依赖：Python 3.10+、常用数据科学库（pandas、numpy、scikit-learn、lightgbm、xgboost、catboost、matplotlib、seaborn、mlflow/optuna 可选）。

## 2. 目录结构规划
```
HullTactical-MarketPredict/
├── README.md
├── requirements.txt / environment.yml
├── kaggle.json                       # Kaggle API 凭证（勿入库）
├── data/
│   ├── raw/                          # 官方原始数据：train.csv, test.csv, sample_submission.csv
│   ├── interim/                      # 清洗后的中间数据
│   ├── processed/                    # 特征工程后的数据/矩阵
│   └── submissions/                  # 最终提交文件
├── notebooks/
│   ├── 01_eda.ipynb
│   ├── 02_feature_prototyping.ipynb
│   └── 03_model_tuning.ipynb
├── configs/
│   ├── paths.yml                     # 数据/模型存放路径
│   ├── features.yml                  # 特征窗口、滞后配置
│   ├── model_lgbm.yml                # LightGBM 超参数
│   └── cv.yml                        # 交叉验证时间切分
├── src/
│   ├── __init__.py
│   ├── data.py                       # 数据加载、校验、预处理
│   ├── features.py                   # 特征工程流水线
│   ├── models.py                     # 模型工厂与训练接口
│   ├── evaluation.py                 # 自定义指标与评估逻辑
│   ├── train.py                      # 训练入口（读配置、保存结果）
│   ├── predict.py                    # 推理入口（生成 submission）
│   └── utils/
│       ├── io.py
│       ├── logging.py
│       └── time_split.py
├── experiments/
│   └── <timestamp_run>/
│       ├── config_snapshot.yml
│       ├── train_metrics.json
│       ├── feature_importance.csv
│       └── model.pkl
├── scripts/
│   ├── make_features.sh
│   ├── train.sh
│   ├── predict.sh
│   └── submit.sh
├── tests/
│   ├── test_data.py
│   ├── test_features.py
│   └── test_time_split.py
└── docs/
    ├── 执行手册.md
    └── eda_report.md (可选)
```

## 3. 执行路线图（TODO 清单）
1. **环境初始化**
   ✅ - 建立虚拟环境： `conda create -n hull python=3.10`。
   ✅ - 安装依赖并验证版本：`pip install -r requirements.txt`。
   ✅ - 设置 Kaggle API：将 `kaggle.json` 放在根目录或 `~/.kaggle/`，授予 600 权限。
2. **数据落地与校验**
   ✅ - 将官方数据复制到 `data/raw/`。
   - 在 `src/data.py` 实现 `load_raw_data()`，校验文件存在、行数/列数、基础缺失率。
   - 输出 `data/interim/train_clean.csv`，记录处理日志。
3. **探索性数据分析（EDA）**
   - 在 `notebooks/01_eda.ipynb` 中分析：目标分布、时间趋势、缺失模式、特征相关性。
   - 生成图表保存至 `reports/figures/`（可新增目录）。
   - 将关键发现写入 `docs/eda_report.md`。
4. **特征工程管线**
   - 在 `configs/features.yml` 定义滞后、滚动窗口、行业聚合、归一化参数。
   - `src/features.py` 实现 `FeatureBuilder` 类，封装 `fit_transform`/`transform`，确保推理可复用。
   - 输出 `data/processed/train_features.parquet`/`test_features.parquet`。
5. **时间切分与评估策略**
   - 在 `configs/cv.yml` 指定 rolling/expanding window 边界日期。
   - `src/utils/time_split.py` 实现时间切分生成器，配合 scikit-learn `TimeSeriesSplit` 接口。
   - `src/evaluation.py` 定义比赛指标（若为 RMSE/自定义收益），并加入辅助指标（准确率、Sharpe 等）。
6. **基线模型构建**
   - 在 `src/models.py` 中提供 `get_model(model_name, params)`，初始支持 Logistic Regression、LightGBM。
   - `train.py` 读取配置：加载特征 → 训练 → 验证 → 输出模型与指标。
   - 将结果写入 `experiments/<timestamp>/`，保存配置快照与特征重要性。
7. **单元测试与质量控制**
   - `tests/test_data.py`：验证缺失值处理、排序是否正确。
   - `tests/test_features.py`：检查特征数量、列名、滞后计算正确。
   - `tests/test_time_split.py`：确保训练集时间 <= 验证集时间。
   - 在 README 记录运行 `pytest` 的命令。
8. **模型优化迭代**
   - 在 `notebooks/02_feature_prototyping.ipynb` 中尝试新特征，回写至配置。
   - 评估多模型：XGBoost、CatBoost、TabNet (可选)；使用 Optuna/Hyperopt 进行超参搜索。
   - 引入集成策略（加权平均、Stacking）；保持实验记录（`experiments/log.csv` 或 MLflow）。
9. **推理与提交流程**
   - `predict.py`：
     1. 载入模型与特征配置。
     2. 构建测试集特征。
     3. 输出 `data/submissions/submission_<run>.csv`。
   - `scripts/submit.sh` 调用 `kaggle competitions submit`，并记录提交 ID 与本地验证分数。
10. **文档与复现保障**
    - 更新 `README.md`：环境、数据下载、训练与推理命令、提交说明、实验日志链接。
    - 在 `docs/` 维护特征字典、模型对比表格。
    - 若时间允许，配置 CI/CD（GitHub Actions）运行 `pytest` + 格式化检查（`black`、`ruff`）。

## 4. 各模块实施细节
### 4.1 数据模块 (`src/data.py`)
- 函数建议：
  - `load_raw(path: Path) -> pd.DataFrame`
  - `validate_schema(df: pd.DataFrame, schema: dict) -> None`
  - `clean_dataframe(df: pd.DataFrame, config: dict) -> pd.DataFrame`
  - `split_by_time(df, train_end, val_end)` 返回 train/val/test。
- 日志：使用 `logging` 模块输出行数、缺失率、异常值统计。
- 输出：保存清洗结果为 Parquet（更快）并记录版本号。

### 4.2 特征模块 (`src/features.py`)
- 设计 `FeatureBuilder`：
  - `__init__(self, config)` 读取窗口长度、滞后列等。
  - `fit(self, df)` 可在训练集计算均值/标准差。
  - `transform(self, df)` 应用到任意时间段数据。
- 常用特征：
  - 滞后收益、成交量（`lag_1/5/10`）。
  - 滚动统计（均值、标准差、偏度、峰度）。
  - 行业/资产组聚合特征（按 ticker 或 sector）。
  - 滚动相关系数、z-score 标准化。
  - 事件/周期特征（周几、月度、季度哑变量）。
- 性能优化：尽量使用 `numba` 或 `pandas.DataFrame.rolling()`，对大窗口分批处理。

### 4.3 模型模块 (`src/models.py`)
- 提供工厂函数：
  ```python
  def get_model(name: str, params: dict):
      if name == "lgbm":
          return lgb.LGBMRegressor(**params)
      if name == "xgb":
          return xgb.XGBRegressor(**params)
      if name == "logreg":
          return LogisticRegression(**params)
      raise ValueError(f"Unknown model {name}")
  ```
- 支持保存/加载：使用 `joblib.dump` 与 `load`。
- 训练脚本中添加早停、特征重要性导出、模型版本号记录。

### 4.4 评估与验证 (`src/evaluation.py`)
- 实现 `evaluate(model, X_val, y_val, metrics: list)`。
- 如果比赛指标与 RMSE 不同（如自定义收益率），需定义对应函数，并在训练与提交评估中复用。
- 输出评估报告至 `experiments/<run>/metrics.json`。

### 4.5 训练与推理脚本
- `train.py` 标准流程：
  1. 解析命令行参数 `--config configs/model_lgbm.yml`。
  2. 读取配置 -> 加载数据 -> 特征处理 -> 切分 -> 模型训练 -> 评估。
  3. 保存模型、特征管线、指标、配置快照。
- `predict.py`：
  1. 读取最新模型路径或作为参数。
  2. 加载测试特征，确保与训练列一致。
  3. 输出预测并校验 `submission.csv` 列名顺序。

## 5. 阶段性目标与交付物
| 阶段 | 完成标准 | 交付物 |
| ---- | -------- | ------ |
| P0 环境 & 数据 | 依赖安装、数据校验通过 | `requirements.txt`, `data/interim/train_clean.csv` |
| P1 EDA | 完成 notebook，结论沉淀 | `notebooks/01_eda.ipynb`, `docs/eda_report.md` |
| P2 特征 | FeatureBuilder 可复用，processed 数据生成 | `data/processed/*.parquet`, `configs/features.yml` |
| P3 基线模型 | 至少一个模型训练成功并记录指标 | `experiments/<run>/...`, README 更新 |
| P4 优化 | 引入 >=2 个新模型/特征，记录对比 | `experiments/log.csv` |
| P5 提交 | 成功生成并提交到 Kaggle | `data/submissions/submission_*.csv`, 提交日志 |

## 6. 风险与应对
- **时间泄露风险**：严格使用时间切分，特征计算仅引用历史窗口；在单元测试中验证。
- **数据漂移**：友好地监控验证集表现，必要时按时间重新训练或调整窗口。
- **过拟合**：交叉验证 + early stopping + 正则；保留简单模型作为 sanity check。
- **计算资源限制**：优先使用高效的 GBDT；对深度模型进行降维、批量训练。
- **复现问题**：所有脚本/配置记录随机种子；使用 `make` 或 `scripts/` 协调运行命令。

## 7. 后续维护建议
- 在 `README.md` 中持续更新“最新最佳模型”章节。
- 若团队协作，使用 Git 分支 + Pull Request + 代码审查。
- 定期整理 `experiments/`，清理过期模型，保留关键版本。
- 关注 Kaggle 讨论区获取特征提示或数据更新信息，并及时纳入手册。
